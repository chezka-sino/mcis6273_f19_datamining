{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["# MCIS6273 Data Mining (Prof. Maull) / Fall 2019 / HW1\n", "\n", "**This assignment is worth up to 25 POINTS to your grade total if you complete it on time.**\n", "\n", "| Points <br/>Possible | Due Date | Time Commitment <br/>(estimated) |\n", "|:---------------:|:--------:|:---------------:|\n", "| 25 | Wednesday, Nov 26 @ Midnight | _up to_ 6 hours |\n", "\n", "\n", "* **GRADING:** Grading will be aligned with the completeness of the objectives.\n", "\n", "* **INDEPENDENT WORK:** Copying, cheating, plagiarism  and academic dishonesty _are not tolerated_ by University or course policy.  Please see the syllabus for the full departmental and University statement on the academic code of honor.\n", "\n", "## OBJECTIVES\n", "* improve on your homework 0 assignment, if necessary\n", "\n", "* work with core Python libraries to do data munging to build a dataset\n", "\n", "* extend your exploration to a larger dataset\n", "\n", "## WHAT TO TURN IN\n", "You are being encouraged to turn the assignment in using the provided\n", "Jupyter Notebook.  To do so, make a directory in your Lab environment called\n", "`homework/hw1`.   Put all of your files in that directory.  Then zip that directory,\n", "rename it with your name as the first part of the filename (e.g. `maull_hw1_files.zip`), then\n", "download it to your local machine, then upload the `.zip` to Blackboard.\n", "\n", "If you do not know how to do this, please ask, or visit one of the many tutorials out there\n", "on the basics of using zip in Linux.\n", "\n", "If you choose not to use the provided notebook, you will still need to turn in a\n", "`.ipynb` Jupyter Notebook and corresponding files according to the instructions in\n", "this homework.\n", "\n", "## ASSIGNMENT TASKS\n", "### (50%) work with core Python libraries to do data munging to build a dataset \n", "\n", "In the last homework, you learned how powerful Pandas is for data engineering, analysis and exploratory\n", "data analysis activities.  We will use it more in this part of the homework to create a  dataset for further analysis.\n", "\n", "Power weightlifting (powerlifting) is an international sport that invites advanced ameteurs and professionals alike.  Fortunately,\n", "there are datasets for the multitude of powerlifting competitions around the world, and they are openly available\n", "for curious data scientists like ourselves who would like to ask interesting questions and find interesting\n", "relationships in the data.  Whether you're into the sport or not, I think there are a variety of\n", "interesting phenomenon in the data that make it both tractable and interesting from just a data perspective.\n", "\n", "**DATA**\n", "\n", "[OpenPowerLifting.org](https://OpenPowerLifting.org) is a large set of data for a multitude of data related to powerlifting\n", "competitions around the world.  The core data live at the following open source repository on [gitlab.com/openpowelifting](https://gitlab.com/openpowerlifting/opl-data).\n", "\n", "For the curious, there are a number of analyses that have already been performed on the data in a number of\n", "interesting ways.  Please visit [this page](https://www.openpowerlifting.org/data) to further fill\n", "your intrigue.\n", "\n", "Though the full dataset is available to us and will be used in the next part of the assignment, we want\n", "to get a little practice getting data from websites that require some HTML parsing and navigation.  Unlike\n", "the last time where we used APIs to get data, we're going to build a dataset _en masse_ from the CSV data\n", "on Gitlab.  Remarkably, while this technique may seem antiquated, you will find many datasets are just\n", "sitting on servers as text files that will require something similar to be accomplished.  We're unfortunately\n", "not yet in a data environment where the most interesting data you want is easily obtained or accessible behind\n", "APIs.  Often the resources to do so are beyond the capabilities of the data providers, though things are\n", "getting better each year with new tools and data access platforms.\n", "\n", "We're going to use Python and the [Beautiful Soup library](https://www.crummy.com/software/BeautifulSoup/)\n", "to build a random dataset of just 2019 data by directly navigating the\n", "HTML of the Gitlab repository.  It will be noted that [Gitlab does have an API](https://docs.gitlab.com/ee/api/),\n", "and it would be the preferred mechanism if we were to do this exercise with APIs like the last assignment.\n", "\n", "&#167;  **BUILD THE DATASET**\n", "\n", "We've learned CSV is common file format for data and we will be working the files large text files in\n", "Gitlab to do the work we need.  The task is to explore the repository and build up a dataset of 15\n", "random lifting meets from 2019 using\n", "[BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) and the tools in Pandas to\n", "put these datasets together.\n", "\n", "This technique is often known as \"crawling\" and is consider by some to\n", "be a flagrant violation of good web etiquette. However, the technique is\n", "still often the only way to obtain data _en masse_ from a single source.\n", "If this were an FTP server, the same pattern could be applied and would\n", "_not_ be considered unusual to do so. Of course, you must use this with\n", "caution, as it can result in IP throttling and IP blocking, so please\n", "use it within the licensing terms of both the data and website you are\n", "obtaining data from. Good web citizens restore trust in providers and\n", "administrators alike, so throttling yourself after your own requests\n", "with code like `time.sleep(2)` (which will pause your code for 2\n", "seconds), will show that you can behave responsibly.\n", "\n", "Once you have loaded all the files, please re-index the rows using the\n", "[`Dataframe.reset_index()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reset_index.html#pandas.DataFrame.reset_index)\n", "method.\n", "\n", "Study the [supplemental Notebook](https://nbviewer.jupyter.org/github/kmsaumcis/mcis6273_f19_datamining/blob/master/homework/hw1/hw1_supplemental.ipynb)\n", "to understand a few ways you may complete your work.\n", "\n", "\n", "&#167;  **GET BASIC DESCRIPTIVE DATA ABOUT THE 2019 RANDOM DATASET**\n", "\n", "Load the dataset from the previous part into a DataFrame and **answer the following questions**:\n", "\n", "* What is _mean_ age of all athletes in your data?\n", "* What is the _median_ age of all athletes?\n", "* What percentage of your data are Women (i.e. `Sex==\"F\"`)?\n", "* What is the _mean_ `Best3BenchKg` for MEN weighing more than 100Kg (i.e. `BodyweightKg>100`)?\n", "* Compare the _median_ `Best3SquatKg` for WOMEN over 40?  And WOMAN under 40?  What difference do you observe?\n", "\n", "To answer the preceding questions, you will need to explore [selection and filtering](http://pandas.pydata.org/pandas-docs/stable/indexing.html)\n", "of DataFrames, with close attention on [`.loc[]`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.loc.html#pandas.DataFrame.loc),\n", "[`.iloc[]`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iloc.html#pandas.DataFrame.iloc) and [`.query()  `](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.query.html#pandas.DataFrame.query).  `.query()` will be especially useful.\n", "\n", "You may also want to carefully explore [`.describe()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html#pandas.DataFrame.describe),\n", "as doing so might reduce your effort considerably.  Your Jupyter Notebook will need to provide **correct and executable cells** for the answers or you will not received\n", "full credit!\n", "\n", "\n", "&#167;  **PLOT THE RELATIONSHIP BETWEEN `Age` AND `TotalKg` USING SEABORN**\n", "\n", "[Seaborn](http://seaborn.pydata.org/index.html) is a visualization library for Python\n", "that \"provides a high-level interface for drawing attractive and informative statistical graphics.\"  It\n", "extends many of the capabilities of matplotlib and has a high degree of polish compared to the\n", "standard plots produced by matplotlib.\n", "\n", "Use Seaborn to plot the relationship between `Age` and `TotalKg` by restricting your\n", "dataset to just `Age` and `TotalKg`.  You may use the code from the supplemental notebook to\n", "get clues on how to do this.  Furthermore, this plot should have the `Age` as the $x$-axis and\n", "`TotalKg` on the $y$-axis. To complete this part, you will need to review the\n", "[`seaborn.jointplot()`](http://seaborn.pydata.org/generated/seaborn.jointplot.html) method.\n", "\n", "* Please write a rationale _using the plot in your analysis_ for the support (or lack of support) for\n", "the claim that _the older an athlete gets the less total weight they will be able to lift_.\n", "\n", "* Derive the correlation between `Age` and `TotalKg` using the [`DataFrame.corr()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html#pandas.DataFrame.corr) method.  Does this\n", "new information change your mind about your previous answer?  Why or why not?  Recall that a positive\n", "correlation greater than $0.5$ would indicate a stronger positive correlation\n", "(a perfect correlation being $1.0$) while the closer to zero indicates no correlation.\n", "\n", "\n", "\n", "### (50%) extend your exploration to a larger dataset \n", "\n", "\n", "Recall, that we said there were reasons to obtain our own datasets when one is not provided for\n", "us.  We're going to extend our data to a much larger dataset to see what kinds of patterns emerge.\n", "\n", "The partial data that we worked with to do  some data munging in the first part comes with some good news!\n", "The friendly community  at OpenPowerLifting have actually made our job even easier\n", "(you will still need to complete the data munging assignment as indicated in the prior section).\n", "\n", "There is a ZIP file with the complete data dump from the most recent competition going\n", "all the way back to the 1960s.  This zip file is <56MB zipped and a few hundred MB unzipped and includes\n", "over 1.3 million records, making this one very interesting data set to explore on a number of fronts.\n", "\n", "We're going to explore the full data set, get some basic exploratory analysis underway and prepare ourselves\n", "for the next homework to do some more sophisticated pattern mining.\n", "\n", "&#167;  **LOAD THE FULL DATASET**\n", "\n", "You are to download the ZIP file from here:\n", "\n", "[openpowerlift-latest.zip](https://github.com/sstangl/openpowerlifting-static/raw/gh-pages/openpowerlifting-latest.zip)\n", "\n", "You are encouraged to use Jupyter shell escaping commands to accmplish this\n", "OR you may open a terminal and use `wget` or `curl` then `unzip`.  You could even write\n", "your own Python code, but this would likely be more effort than necessary for this\n", "assignment. See the supplemental notebook for more information on shell escaping.\n", "\n", "\n", "&#167;  **COMPUTE THE TOTAL PERCENT MEN AND WOMEN COMPETITORS FROM 1964**\n", "\n", "Female participation in powerlifting has grown over the years and now women powerlifters are\n", "commonplace in competitive meets.  You are to look into the growth of female participation\n", "given the dataset in the OpenPowerLifting data.\n", "\n", "You should begin using the function below that takes the original data from the first part of\n", "this section and returns a Dataframe with the ratio of male to female participants.\n", "\n", "```python\n", "\n", "def get_gender_ratios(df, year):\n", "    return \\\n", "        df.query('Date>\"{}-01-01\" & Date<\"{}-01-01\"'.format(year, year+1)).loc[:,['Sex']].squeeze().value_counts() \\\n", "            / df.query('Date>\"{}-01-01\" & Date<\"{}-01-01\"'.format(year, year+1)).loc[:,['Sex']].shape[0]\n", "```\n", "\n", "Thus,\n", "\n", "```\n", "> get_gender_ratios(df, 1964)\n", "\n", "M    1.0\n", "Name: Sex, dtype: float64\n", "```\n", "Meaning, 100% of the participant data for 1964 were Male.\n", "\n", "\n", "* You will need to use the function to build a Dataframe with all the years and ratios.  Your final\n", "Dataframe will have two rows 'M' and 'F' and the columns will be the years.  See the supplied\n", "notebook to see an example.  Using that you will be able to transpose the data to complete the remaining\n", "plots and questions.  See the [`.T`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.T.html#pandas.DataFrame.T) method to determine what transposing does.\n", "\n", "* Build the Dataframe with all the percentages from 1964 to 2019.\n", "\n", "\n", "&#167;  **PLOT THE MALE/FEMALE RATIOS AND ANSWER THE QUESTIONS**\n", "\n", "* From the previous result, you were able to compute the ratios.  Now plot them.  The simplest way\n", "is to use the [`Dataframe.plot(kind='line')`](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html) where the `Dataframe` is the transposed data\n", "from the prior section.  Your notebook MUST show the plot for full points.\n", "* Explain in your own words what _overall_ trend that you see in the data.\n", "* When  were the greatest participation increases in women powerlifters?\n", "* Describe in your own words you see between the years 2009-2012?\n", "\n", "\n", "\n"]}], "metadata": {"anaconda-cloud": {}, "kernelspec": {"display_name": "Python [default]", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.1"}, "toc": {"colors": {"hover_highlight": "#DAA520", "navigate_num": "#000000", "navigate_text": "#333333", "running_highlight": "#FF0000", "selected_highlight": "#FFD700", "sidebar_border": "#EEEEEE", "wrapper_background": "#FFFFFF"}, "moveMenuLeft": true, "nav_menu": {"height": "12px", "width": "252px"}, "navigate_menu": true, "number_sections": false, "sideBar": true, "threshold": "1", "toc_cell": false, "toc_section_display": "block", "toc_window_display": true, "widenNotebook": false}}, "nbformat": 4, "nbformat_minor": 0}